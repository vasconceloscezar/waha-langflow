{"id":"41ed22f9-45e6-4671-98b3-d94b7bd59a5b","data":{"nodes":[{"id":"WAHAMessageParser-vFNUP","type":"genericNode","position":{"x":3577.9535684029056,"y":1146.0829411025923},"data":{"type":"WAHAMessageParser","node":{"template":{"_type":"Component","input_data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"input_data","value":"","display_name":"Input Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"A Data object containing a 'payload' field with the WhatsApp message data.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\r\nfrom typing import Union, Dict, Any\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\nfrom loguru import logger\r\n\r\nclass WAHAMessageParserComponent(Component):\r\n    display_name = \"WAHA Message Parser\"\r\n    description = \"Parses a WhatsApp message from a Data input and provides multiple outputs for different parts of the message.\"\r\n    icon = \"message-square-code\"\r\n    name = \"WAHAMessageParser\"\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"input_data\",\r\n            display_name=\"Input Data\",\r\n            info=\"A Data object containing a 'payload' field with the WhatsApp message data.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Full Message\", name=\"full_message\", method=\"full_message_response\"),\r\n        Output(display_name=\"Message ID\", name=\"message_id\", method=\"message_id_response\"),\r\n        Output(display_name=\"Timestamp\", name=\"timestamp\", method=\"timestamp_response\"),\r\n        Output(display_name=\"From\", name=\"from\", method=\"from_response\"),\r\n        Output(display_name=\"From Me\", name=\"from_me\", method=\"from_me_response\"),\r\n        Output(display_name=\"To\", name=\"to\", method=\"to_response\"),\r\n        Output(display_name=\"Participant\", name=\"participant\", method=\"participant_response\"),\r\n        Output(display_name=\"Body\", name=\"body\", method=\"body_response\"),\r\n        Output(display_name=\"Has Media\", name=\"has_media\", method=\"has_media_response\"),\r\n        Output(display_name=\"Media\", name=\"media\", method=\"media_response\"),\r\n        Output(display_name=\"Ack\", name=\"ack\", method=\"ack_response\"),\r\n        Output(display_name=\"Ack Name\", name=\"ack_name\", method=\"ack_name_response\"),\r\n        Output(display_name=\"Author\", name=\"author\", method=\"author_response\"),\r\n        Output(display_name=\"Location\", name=\"location\", method=\"location_response\"),\r\n        Output(display_name=\"vCards\", name=\"vcards\", method=\"vcards_response\"),\r\n        Output(display_name=\"Reply To\", name=\"reply_to\", method=\"reply_to_response\"),\r\n    ]\r\n\r\n    def validate_input(self) -> Dict[str, Any]:\r\n        logger.info(\"Starting input validation\")\r\n        \r\n        if not isinstance(self.input_data, Data):\r\n            logger.error(f\"Invalid input type: {type(self.input_data)}. Expected Data object.\")\r\n            raise ValueError(\"Input must be a Data object.\")\r\n        \r\n        payload = self.input_data.data.get(\"payload\")\r\n        if not payload:\r\n            logger.error(\"No 'payload' field found in the input Data object.\")\r\n            raise ValueError(\"Input Data object must contain a 'payload' field.\")\r\n        \r\n        if not isinstance(payload, dict):\r\n            logger.error(f\"Invalid payload type: {type(payload)}. Expected dictionary.\")\r\n            raise ValueError(\"Payload must be a dictionary.\")\r\n        \r\n        return payload\r\n\r\n    def full_message_response(self) -> Data:\r\n        logger.info(\"Providing full message response\")\r\n        parsed_data = self.validate_input()\r\n        return Data(data=parsed_data)\r\n\r\n    def message_id_response(self) -> Message:\r\n        logger.info(\"Providing message ID response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=parsed_data.get(\"id\", \"\"))\r\n\r\n    def timestamp_response(self) -> Message:\r\n        logger.info(\"Providing timestamp response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=str(parsed_data.get(\"timestamp\", 0)))\r\n\r\n    def from_response(self) -> Message:\r\n        logger.info(\"Providing 'from' response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=parsed_data.get(\"from\", \"\"))\r\n\r\n    def from_me_response(self) -> Message:\r\n        logger.info(\"Providing 'fromMe' response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=str(parsed_data.get(\"fromMe\", False)))\r\n\r\n    def to_response(self) -> Message:\r\n        logger.info(\"Providing 'to' response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=parsed_data.get(\"to\", \"\"))\r\n\r\n    def participant_response(self) -> Message:\r\n        logger.info(\"Providing participant response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=parsed_data.get(\"participant\", \"\"))\r\n\r\n    def body_response(self) -> Message:\r\n        logger.info(\"Providing body response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=parsed_data.get(\"body\", \"\"))\r\n\r\n    def has_media_response(self) -> Message:\r\n        logger.info(\"Providing hasMedia response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=str(parsed_data.get(\"hasMedia\", False)))\r\n\r\n    def media_response(self) -> Data:\r\n        logger.info(\"Providing media response\")\r\n        parsed_data = self.validate_input()\r\n        return Data(data=parsed_data.get(\"media\", {}))\r\n\r\n    def ack_response(self) -> Message:\r\n        logger.info(\"Providing ack response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=str(parsed_data.get(\"ack\", \"\")))\r\n\r\n    def ack_name_response(self) -> Message:\r\n        logger.info(\"Providing ackName response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=parsed_data.get(\"ackName\", \"\"))\r\n\r\n    def author_response(self) -> Message:\r\n        logger.info(\"Providing author response\")\r\n        parsed_data = self.validate_input()\r\n        return Message(text=parsed_data.get(\"author\", \"\"))\r\n\r\n    def location_response(self) -> Data:\r\n        logger.info(\"Providing location response\")\r\n        parsed_data = self.validate_input()\r\n        return Data(data=parsed_data.get(\"location\", {}))\r\n\r\n    def vcards_response(self) -> Data:\r\n        logger.info(\"Providing vCards response\")\r\n        parsed_data = self.validate_input()\r\n        return Data(data={\"vCards\": parsed_data.get(\"vCards\", [])})\r\n\r\n    def reply_to_response(self) -> Data:\r\n        logger.info(\"Providing reply_to response\")\r\n        parsed_data = self.validate_input()\r\n        return Data(data=parsed_data.get(\"replyTo\", {}))\r\n\r\n    def build(self) -> Dict[str, Union[Message, Data]]:\r\n        logger.info(\"Building component outputs\")\r\n        parsed_data = self.validate_input()\r\n        return {\r\n            \"full_message\": Data(data=parsed_data),\r\n            \"message_id\": Message(text=parsed_data.get(\"id\", \"\")),\r\n            \"timestamp\": Message(text=str(parsed_data.get(\"timestamp\", 0))),\r\n            \"from\": Message(text=parsed_data.get(\"from\", \"\")),\r\n            \"from_me\": Message(text=str(parsed_data.get(\"fromMe\", False))),\r\n            \"to\": Message(text=parsed_data.get(\"to\", \"\")),\r\n            \"participant\": Message(text=parsed_data.get(\"participant\", \"\")),\r\n            \"body\": Message(text=parsed_data.get(\"body\", \"\")),\r\n            \"has_media\": Message(text=str(parsed_data.get(\"hasMedia\", False))),\r\n            \"media\": Data(data=parsed_data.get(\"media\", {})),\r\n            \"ack\": Message(text=str(parsed_data.get(\"ack\", \"\"))),\r\n            \"ack_name\": Message(text=parsed_data.get(\"ackName\", \"\")),\r\n            \"author\": Message(text=parsed_data.get(\"author\", \"\")),\r\n            \"location\": Data(data=parsed_data.get(\"location\", {})),\r\n            \"vcards\": Data(data={\"vCards\": parsed_data.get(\"vCards\", [])}),\r\n            \"reply_to\": Data(data=parsed_data.get(\"replyTo\", {})),\r\n        }","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Parses a WhatsApp message from a Data input and provides multiple outputs for different parts of the message.","icon":"message-square-code","base_classes":["Data","Message"],"display_name":"WAHA - Message Payload","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"full_message","display_name":"Full Message","method":"full_message_response","value":"__UNDEFINED__","cache":true,"hidden":false},{"types":["Message"],"selected":"Message","name":"message_id","display_name":"Message ID","method":"message_id_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"timestamp","display_name":"Timestamp","method":"timestamp_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"from","display_name":"From","method":"from_response","value":"__UNDEFINED__","cache":true},{"types":["Message"],"selected":"Message","name":"from_me","display_name":"From Me","method":"from_me_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"to","display_name":"To","method":"to_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"participant","display_name":"Participant","method":"participant_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"body","display_name":"Body","method":"body_response","value":"__UNDEFINED__","cache":true},{"types":["Message"],"selected":"Message","name":"has_media","display_name":"Has Media","method":"has_media_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Data"],"selected":"Data","name":"media","display_name":"Media","method":"media_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"ack","display_name":"Ack","method":"ack_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"ack_name","display_name":"Ack Name","method":"ack_name_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Message"],"selected":"Message","name":"author","display_name":"Author","method":"author_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Data"],"selected":"Data","name":"location","display_name":"Location","method":"location_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Data"],"selected":"Data","name":"vcards","display_name":"vCards","method":"vcards_response","value":"__UNDEFINED__","cache":true,"hidden":true},{"types":["Data"],"selected":"Data","name":"reply_to","display_name":"Reply To","method":"reply_to_response","value":"__UNDEFINED__","cache":true,"hidden":true}],"field_order":["input_data"],"beta":false,"edited":true,"lf_version":"1.0.17"},"id":"WAHAMessageParser-vFNUP"},"selected":false,"width":384,"height":911},{"id":"ConditionalRouter-5qC0k","type":"genericNode","position":{"x":4193.861757375784,"y":1116.0054028557313},"data":{"type":"ConditionalRouter","node":{"template":{"_type":"Component","case_sensitive":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"case_sensitive","value":false,"display_name":"Case Sensitive","advanced":true,"dynamic":false,"info":"If true, the comparison will be case sensitive.","title_case":false,"type":"bool","_input_type":"BoolInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"equal\"\n    name = \"ConditionalRouter\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The primary text input for the operation.\",\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Route\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False Route\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, case_sensitive: bool) -> bool:\n        if not case_sensitive:\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        elif operator == \"not equals\":\n            return input_text != match_text\n        elif operator == \"contains\":\n            return match_text in input_text\n        elif operator == \"starts with\":\n            return input_text.startswith(match_text)\n        elif operator == \"ends with\":\n            return input_text.endswith(match_text)\n        return False\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"true_result\")\n            return None  # type: ignore\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if not result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"false_result\")\n            return None  # type: ignore\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_text":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_text","value":"","display_name":"Input Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The primary text input for the operation.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"match_text":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"match_text","value":"number-id-here","display_name":"Match Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The text input to compare against.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"message","value":"","display_name":"Message","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The message to pass through either route.","title_case":false,"type":"str","_input_type":"MessageInput"},"operator":{"trace_as_metadata":true,"options":["equals","not equals","contains","starts with","ends with"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"operator","value":"equals","display_name":"Operator","advanced":true,"dynamic":false,"info":"The operator to apply for comparing the texts.","title_case":false,"type":"str","_input_type":"DropdownInput"}},"description":"Routes an input message to a corresponding output based on text comparison.","icon":"equal","base_classes":["Message"],"display_name":"Conditional Router","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"true_result","display_name":"True Route","method":"true_response","value":"__UNDEFINED__","cache":true},{"types":["Message"],"selected":"Message","name":"false_result","display_name":"False Route","method":"false_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_text","match_text","operator","case_sensitive","message"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"ConditionalRouter-5qC0k"},"selected":false,"width":384,"height":537},{"id":"OpenAIModel-m3c5s","type":"genericNode","position":{"x":7588.397861592814,"y":2090.6248443973236},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"json_mode","value":false,"display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gpt-4o","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"output_schema","value":{},"display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"seed","value":1,"display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"OpenAIModel-m3c5s"},"selected":false,"width":384,"height":595},{"id":"Prompt-1ADTy","type":"genericNode","position":{"x":7061.353572233802,"y":2373.831277350445},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"Using the same pattern of these messages: \n\n{old_messages}\n\nAgain, follow the same pattern, writing style, punctuation, etc. \n\n\nFollow the structure, like, if the conversation uses lowercase often use as well. \nbe casual, like you would be talking to a friend \n\n\nReply to this message in the same language the conversation is, same style and tone: \nONLY REPLY TO THE LAST MESSAGE\n{message} \n","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput"},"message":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"message","display_name":"message","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"old_messages":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"old_messages","display_name":"old_messages","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["old_messages","message"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false,"lf_version":"1.0.17"},"id":"Prompt-1ADTy"},"selected":false,"width":384,"height":497},{"id":"WAHAGetChatMessagesComponent-JSlLF","type":"genericNode","position":{"x":6022.026359788506,"y":3007.233670842441},"data":{"type":"WAHAGetChatMessagesComponent","node":{"template":{"_type":"Component","base_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"base_url","value":"http://api-whatsapp.namastex.ai:3000","display_name":"Base URL","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The base URL of the WAHA API.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"chat_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"chat_id","value":"","display_name":"Chat ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The ID of the chat to retrieve messages from.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import httpx\r\nfrom typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.inputs import MessageTextInput, IntInput, BoolInput, DropdownInput\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass WAHAGetChatMessagesComponent(LCToolComponent):\r\n    display_name = \"WAHA - Get Chat Messages\"\r\n    description = \"Retrieves messages from a specific chat in the WAHA API.\"\r\n    icon = \"message-circle-more\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"base_url\",\r\n            display_name=\"Base URL\",\r\n            info=\"The base URL of the WAHA API.\",\r\n            value=\"http://localhost:3000\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"session\",\r\n            display_name=\"Session\",\r\n            info=\"The session name.\",\r\n            value=\"default\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"chat_id\",\r\n            display_name=\"Chat ID\",\r\n            info=\"The ID of the chat to retrieve messages from.\",\r\n        ),\r\n        IntInput(\r\n            name=\"limit\",\r\n            display_name=\"Limit\",\r\n            info=\"The maximum number of messages to retrieve.\",\r\n            value=100,\r\n        ),\r\n        BoolInput(\r\n            name=\"download_media\",\r\n            display_name=\"Download Media\",\r\n            info=\"Whether to download media for messages.\",\r\n            value=False,\r\n        ),\r\n        DropdownInput(\r\n            name=\"message_filter\",\r\n            display_name=\"Message Filter\",\r\n            options=[\"all\", \"from_me\", \"from_others\"],\r\n            value=\"all\",\r\n            info=\"Filter messages based on sender.\",\r\n        ),\r\n    ]\r\n\r\n    class WAHAGetChatMessagesSchema(BaseModel):\r\n        chat_id: str = Field(..., description=\"The ID of the chat to retrieve messages from.\")\r\n        limit: int = Field(100, description=\"The maximum number of messages to retrieve.\")\r\n        download_media: bool = Field(False, description=\"Whether to download media for messages.\")\r\n        message_filter: str = Field(\"all\", description=\"Filter messages based on sender.\")\r\n\r\n    def run_model(self) -> List[Data]:\r\n        messages = self._get_chat_messages(\r\n            self.chat_id, \r\n            self.limit, \r\n            self.download_media, \r\n            self.message_filter\r\n        )\r\n        return [Data(data=message) for message in messages]\r\n\r\n    def build_tool(self) -> Tool:\r\n        return StructuredTool.from_function(\r\n            name=\"waha_get_chat_messages\",\r\n            description=\"Retrieves messages from a specific chat in the WAHA API.\",\r\n            func=self._get_chat_messages,\r\n            args_schema=self.WAHAGetChatMessagesSchema,\r\n        )\r\n\r\n    def _get_chat_messages(\r\n        self, \r\n        chat_id: str, \r\n        limit: int = 100, \r\n        download_media: bool = False,\r\n        message_filter: str = \"all\"\r\n    ) -> List[Dict[str, Any]]:\r\n        url = f\"{self.base_url}/api/{self.session}/chats/{chat_id}/messages\"\r\n        params = {\r\n            \"limit\": limit,\r\n            \"downloadMedia\": download_media,\r\n        }\r\n        headers = {\r\n            \"X-Api-Key\": \"{{apiKey}}\",  # Replace with actual API key handling\r\n        }\r\n        \r\n        self.log(f\"Sending GET request to {url}\")\r\n        with httpx.Client() as client:\r\n            response = client.get(url, params=params, headers=headers)\r\n        \r\n        response.raise_for_status()\r\n        messages = response.json()\r\n        \r\n        # Apply message filter\r\n        if message_filter == \"from_me\":\r\n            messages = [msg for msg in messages if msg.get(\"fromMe\", False)]\r\n        elif message_filter == \"from_others\":\r\n            messages = [msg for msg in messages if not msg.get(\"fromMe\", False)]\r\n        \r\n        self.log(f\"Retrieved {len(messages)} messages after filtering\")\r\n        return messages","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"download_media":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"download_media","value":false,"display_name":"Download Media","advanced":false,"dynamic":false,"info":"Whether to download media for messages.","title_case":false,"type":"bool","_input_type":"BoolInput"},"limit":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"limit","value":1000,"display_name":"Limit","advanced":false,"dynamic":false,"info":"The maximum number of messages to retrieve.","title_case":false,"type":"int","_input_type":"IntInput","load_from_db":false},"message_filter":{"trace_as_metadata":true,"options":["all","from_me","from_others"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"message_filter","value":"from_me","display_name":"Message Filter","advanced":false,"dynamic":false,"info":"Filter messages based on sender.","title_case":false,"type":"str","_input_type":"DropdownInput"},"session":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"session","value":"default","display_name":"Session","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The session name.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Retrieves messages from a specific chat in the WAHA API.","icon":"message-circle-more","base_classes":["Data","Tool"],"display_name":"WAHA - Get Chat Messages","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"api_run_model","display_name":"Data","method":"run_model","value":"__UNDEFINED__","cache":true},{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["base_url","session","chat_id","limit","download_media","message_filter"],"beta":false,"edited":true,"lf_version":"1.0.17"},"id":"WAHAGetChatMessagesComponent-JSlLF"},"selected":true,"width":384,"height":781},{"id":"ParseData-ztNLm","type":"genericNode","position":{"x":6554.310765277454,"y":2940.431308011921},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"{body}","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"ParseData-ztNLm"},"selected":false,"width":384,"height":369},{"id":"WAHASendTextMessageComponent-n5hG9","type":"genericNode","position":{"x":8090.901995083439,"y":2467.628264246998},"data":{"type":"WAHASendTextMessageComponent","node":{"template":{"_type":"Component","base_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"base_url","value":"http://api-whatsapp.namastex.ai:3000","display_name":"Base URL","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The base URL of the WAHA API.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"chat_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"chat_id","value":"","display_name":"Chat ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The ID of the chat to send the message to.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import httpx\r\nfrom typing import Dict, Any, Optional\r\nfrom pydantic import BaseModel, Field\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.inputs import MessageTextInput\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass WAHASendTextMessageComponent(LCToolComponent):\r\n    display_name = \"WAHA - Send Text Message\"\r\n    description = \"Sends a text message to a specific chat using the WAHA API.\"\r\n    icon = \"message-circle-more\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"base_url\",\r\n            display_name=\"Base URL\",\r\n            info=\"The base URL of the WAHA API.\",\r\n            value=\"http://localhost:3000\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"session\",\r\n            display_name=\"Session\",\r\n            info=\"The session name.\",\r\n            value=\"default\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"chat_id\",\r\n            display_name=\"Chat ID\",\r\n            info=\"The ID of the chat to send the message to.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"text\",\r\n            display_name=\"Message Text\",\r\n            info=\"The text content of the message to send.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"reply_to\",\r\n            display_name=\"Reply To\",\r\n            info=\"The ID of the message to reply to (optional).\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    class WAHASendTextMessageSchema(BaseModel):\r\n        chat_id: str = Field(..., description=\"The ID of the chat to send the message to.\")\r\n        text: str = Field(..., description=\"The text content of the message to send.\")\r\n        reply_to: Optional[str] = Field(None, description=\"The ID of the message to reply to (optional).\")\r\n\r\n    def run_model(self) -> Data:\r\n        sent_message = self._send_text_message(self.chat_id, self.text, self.reply_to)\r\n        return Data(data=sent_message)\r\n\r\n    def build_tool(self) -> Tool:\r\n        return StructuredTool.from_function(\r\n            name=\"waha_send_text_message\",\r\n            description=\"Sends a text message to a specific chat using the WAHA API.\",\r\n            func=self._send_text_message,\r\n            args_schema=self.WAHASendTextMessageSchema,\r\n        )\r\n\r\n    def _send_text_message(self, chat_id: str, text: str, reply_to: Optional[str] = None) -> Dict[str, Any]:\r\n        url = f\"{self.base_url}/api/sendText\"\r\n        payload = {\r\n            \"chatId\": chat_id,\r\n            \"text\": text,\r\n            \"session\": self.session,\r\n        }\r\n        if reply_to:\r\n            payload[\"reply_to\"] = reply_to\r\n\r\n        headers = {\r\n            \"X-Api-Key\": \"{{apiKey}}\",  # Replace with actual API key handling\r\n            \"Content-Type\": \"application/json\",\r\n        }\r\n\r\n        self.log(f\"Sending POST request to {url}\")\r\n        with httpx.Client() as client:\r\n            response = client.post(url, json=payload, headers=headers)\r\n        response.raise_for_status()\r\n        sent_message = response.json()\r\n\r\n        self.log(\"Message sent successfully\")\r\n        return sent_message","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"reply_to":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"reply_to","value":"","display_name":"Reply To","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The ID of the message to reply to (optional).","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"session","value":"default","display_name":"Session","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The session name.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"text":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"text","value":"","display_name":"Message Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The text content of the message to send.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Sends a text message to a specific chat using the WAHA API.","icon":"message-circle-more","base_classes":["Data","Tool"],"display_name":"WAHA - Send Text Message","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"api_run_model","display_name":"Data","method":"run_model","value":"__UNDEFINED__","cache":true},{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["base_url","session","chat_id","text","reply_to"],"beta":false,"edited":true,"lf_version":"1.0.17","official":false},"id":"WAHASendTextMessageComponent-n5hG9"},"selected":false,"width":384,"height":623},{"id":"AnthropicModel-KryHb","type":"genericNode","position":{"x":7575.53618726511,"y":2745.296643092901},"data":{"type":"AnthropicModel","node":{"template":{"_type":"Component","anthropic_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"anthropic_api_key","value":"","display_name":"Anthropic API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Your Anthropic API key.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"anthropic_api_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"anthropic_api_url","value":"","display_name":"Anthropic API URL","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_anthropic.chat_models import ChatAnthropic\n        except ImportError:\n            raise ImportError(\n                \"langchain_anthropic is not installed. Please install it with `pip install langchain_anthropic`.\"\n            )\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":4096,"display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model":{"trace_as_metadata":true,"options":["claude-3-5-sonnet-20240620","claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model","value":"claude-3-5-sonnet-20240620","display_name":"Model Name","advanced":false,"dynamic":false,"info":"https://python.langchain.com/docs/integrations/chat/anthropic","title_case":false,"type":"str","_input_type":"DropdownInput"},"prefill":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"prefill","value":"","display_name":"Prefill","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Prefill text to guide the model's response.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generate text using Anthropic Chat&Completion LLMs with prefill support.","icon":"Anthropic","base_classes":["LanguageModel","Message"],"display_name":"Anthropic","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model","anthropic_api_key","temperature","anthropic_api_url","prefill"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"AnthropicModel-KryHb"},"selected":false,"width":384,"height":623},{"id":"TextInput-QYRO0","type":"genericNode","position":{"x":1094,"y":800.8307758435647},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"{\n      \"event\": \"message\",\n      \"session\": \"default\",\n      \"metadata\": {},\n      \"me\": {\n        \"id\": \"555197285829@c.us\",\n        \"pushName\": \"Cezar Augusto\"\n      },\n      \"payload\": {\n        \"id\": \"false_555199550002@c.us_ACD76310E64C565FD2\",\n        \"timestamp\": 1725556865,\n        \"from\": \"555199550002@c.us\",\n        \"fromMe\": false,\n        \"to\": \"555197285829@c.us\",\n        \"body\": \"Obrigado(a) por aguardar! Estamos recebendo um grande volume de atendimentos no momento, então seu tempo de espera pode ser um pouco mais longo. Mas fique tranquilo(a), faremos o nosso melhor para atendê-lo(a) assim que possível. Você está na posição 5 da fila. Por favor, permaneça no aguardo ou, se precisar sair, basta digitar 'ENCERRAR'. Nos desculpe pelo inconveniente e agradecemos sua compreensão\",\n        \"hasMedia\": false,\n        \"ack\": 1,\n        \"ackName\": \"SERVER\",\n        \"vCards\": [],\n        \"_data\": {\n          \"id\": {\n            \"fromMe\": false,\n            \"remote\": \"555199550002@c.us\",\n            \"id\": \"ACD76310E64C565FD2\",\n            \"_serialized\": \"false_555199550002@c.us_ACD76310E64C565FD2\"\n          },\n          \"viewed\": false,\n          \"body\": \"Obrigado(a) por aguardar! Estamos recebendo um grande volume de atendimentos no momento, então seu tempo de espera pode ser um pouco mais longo. Mas fique tranquilo(a), faremos o nosso melhor para atendê-lo(a) assim que possível. Você está na posição 5 da fila. Por favor, permaneça no aguardo ou, se precisar sair, basta digitar 'ENCERRAR'. Nos desculpe pelo inconveniente e agradecemos sua compreensão\",\n          \"type\": \"chat\",\n          \"t\": 1725556865,\n          \"notifyName\": \"555199550002\",\n          \"from\": \"555199550002@c.us\",\n          \"to\": \"555197285829@c.us\",\n          \"ack\": 1,\n          \"invis\": false,\n          \"isNewMsg\": true,\n          \"star\": false,\n          \"kicNotified\": false,\n          \"recvFresh\": true,\n          \"isFromTemplate\": false,\n          \"pollInvalidated\": false,\n          \"isSentCagPollCreation\": false,\n          \"latestEditMsgKey\": null,\n          \"latestEditSenderTimestampMs\": null,\n          \"mentionedJidList\": [],\n          \"groupMentions\": [],\n          \"isEventCanceled\": false,\n          \"eventInvalidated\": false,\n          \"isVcardOverMmsDocument\": false,\n          \"isForwarded\": false,\n          \"hasReaction\": false,\n          \"privacyModeWhenSent\": {\n            \"actualActors\": 2,\n            \"hostStorage\": 1,\n            \"privacyModeTs\": 1619097475\n          },\n          \"productHeaderImageRejected\": false,\n          \"lastPlaybackProgress\": 0,\n          \"isDynamicReplyButtonsMsg\": false,\n          \"isCarouselCard\": false,\n          \"parentMsgId\": null,\n          \"isMdHistoryMsg\": false,\n          \"stickerSentTs\": 0,\n          \"isAvatar\": false,\n          \"lastUpdateFromServerTs\": 0,\n          \"invokedBotWid\": null,\n          \"bizBotType\": null,\n          \"botResponseTargetId\": null,\n          \"botPluginType\": null,\n          \"botPluginReferenceIndex\": null,\n          \"botPluginSearchProvider\": null,\n          \"botPluginSearchUrl\": null,\n          \"botPluginSearchQuery\": null,\n          \"botPluginMaybeParent\": false,\n          \"botReelPluginThumbnailCdnUrl\": null,\n          \"botMsgBodyType\": null,\n          \"requiresDirectConnection\": null,\n          \"bizContentPlaceholderType\": null,\n          \"hostedBizEncStateMismatch\": false,\n          \"senderOrRecipientAccountTypeHosted\": false,\n          \"placeholderCreatedWhenAccountIsHosted\": false,\n          \"links\": []\n        }\n      },\n      \"engine\": \"WEBJS\",\n      \"environment\": {\n        \"version\": \"2024.9.2\",\n        \"engine\": \"WEBJS\",\n        \"tier\": \"CORE\",\n        \"browser\": \"/usr/bin/chromium\"\n      }\n    }","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Should Not Rply","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"TextInput-QYRO0","description":"Get text inputs from the Playground.","display_name":"Text Input"},"selected":false,"width":384,"height":297},{"id":"AnthropicModel-2Z3iK","type":"genericNode","position":{"x":2061.5787380911715,"y":986.2308757440258},"data":{"type":"AnthropicModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\r\nfrom typing import Union, List\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass JSONToDataComponent(Component):\r\n    display_name = \"JSON to Data\"\r\n    description = \"Convert a JSON string to a Data object or a list of Data objects\"\r\n    icon = \"🔃\"\r\n\r\n    inputs = [\r\n        MessageInput(\r\n            name=\"json_string\",\r\n            display_name=\"JSON String\",\r\n            info=\"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"data\", display_name=\"Data\", method=\"convert_json_to_data\"),\r\n    ]\r\n\r\n    def convert_json_to_data(self) -> Union[Data, List[Data]]:\r\n        try:\r\n            json_string = self.json_string.text\r\n\r\n            # Try to parse the JSON string\r\n            try:\r\n                parsed_data = json.loads(json_string)\r\n            except json.JSONDecodeError:\r\n                # If JSON parsing fails, try to evaluate it as a Python literal\r\n                import ast\r\n                parsed_data = ast.literal_eval(json_string)\r\n\r\n            # Check if the parsed data is a list\r\n            if isinstance(parsed_data, list):\r\n                result = [Data(data=item) for item in parsed_data]\r\n            else:\r\n                result = Data(data=parsed_data)\r\n\r\n            self.status = result\r\n            return result\r\n\r\n        except (json.JSONDecodeError, SyntaxError, ValueError) as e:\r\n            error_message = f\"Invalid JSON or Python literal: {str(e)}\"\r\n            error_data = Data(data={\"error\": error_message})\r\n            self.status = error_data\r\n            return error_data\r\n\r\n        except Exception as e:\r\n            error_message = f\"An error occurred: {str(e)}\"\r\n            error_data = Data(data={\"error\": error_message})\r\n            self.status = error_data\r\n            return error_data","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"json_string":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"json_string","display_name":"JSON String","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects","title_case":false,"type":"str"}},"description":"Convert a JSON string to a Data object or a list of Data objects","icon":"🔃","base_classes":["Data","List"],"display_name":"JSON to Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data","List"],"selected":"Data","name":"data","display_name":"Data","method":"convert_json_to_data","value":"__UNDEFINED__","cache":true}],"field_order":["json_string"],"beta":false,"edited":true,"official":false,"lf_version":"1.0.17"},"id":"AnthropicModel-2Z3iK"},"selected":false,"width":384,"height":321},{"id":"Prompt-EuZGR","type":"genericNode","position":{"x":4705.3418857187935,"y":901.7601482367361},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"You will recieve messages like: \n\n\n___\nObrigado(a) por aguardar! Estamos recebendo um grande volume de atendimentos no momento, então seu tempo de espera pode ser um pouco mais longo. Mas fique tranquilo(a), faremos o nosso melhor para atendê-lo(a) assim que possível. Você está na posição 5 da fila. Por favor, permaneça no aguardo ou, se precisar sair, basta digitar 'ENCERRAR'. Nos desculpe pelo inconveniente e agradecemos sua compreensão\n____\n\n\nWhen its your time you will recieve something like: \n\n____\nOi, meu nome é RODRIGO. Em que posso ajudar? \nSe ficarmos sem interação por 5 minutos, nossa conversa será automaticamente encerrada.\n___\n\nIf the message is the form the support already talking about something else, you should not reply, you should only reply to the greetings and the message that talks about \"Se ficarmos sem interação por 5 minutos, nossa conversa será automaticamente encerrada.\"\n\n\nMessage: \n\n______\n{message}\n______\n\n\nSo, your task is to return a JSON string containing: \n\n\"reasoning\": \"where you briefly explain why should or not should reply\"\n\"should_reply\": true/false\n\n\nReply only with a valid JSON string, no need to put inside code blocks.","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput"},"message":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"message","display_name":"message","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["message"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-EuZGR"},"selected":false,"width":384,"height":411},{"id":"OpenAIModel-828dg","type":"genericNode","position":{"x":5218.677913784011,"y":696.0907538332615},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"json_mode","value":false,"display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gpt-4o-mini","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"output_schema","value":{},"display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"seed","value":1,"display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"OpenAIModel-828dg"},"selected":false,"width":384,"height":595},{"id":"AnthropicModel-E1MBw","type":"genericNode","position":{"x":5696.881078056131,"y":760.3710003677377},"data":{"type":"AnthropicModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\r\nfrom typing import Union, List\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass JSONToDataComponent(Component):\r\n    display_name = \"JSON to Data\"\r\n    description = \"Convert a JSON string to a Data object or a list of Data objects\"\r\n    icon = \"🔃\"\r\n\r\n    inputs = [\r\n        MessageInput(\r\n            name=\"json_string\",\r\n            display_name=\"JSON String\",\r\n            info=\"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"data\", display_name=\"Data\", method=\"convert_json_to_data\"),\r\n    ]\r\n\r\n    def convert_json_to_data(self) -> Union[Data, List[Data]]:\r\n        try:\r\n            json_string = self.json_string.text\r\n\r\n            # Try to parse the JSON string\r\n            try:\r\n                parsed_data = json.loads(json_string)\r\n            except json.JSONDecodeError:\r\n                # If JSON parsing fails, try to evaluate it as a Python literal\r\n                import ast\r\n                parsed_data = ast.literal_eval(json_string)\r\n\r\n            # Check if the parsed data is a list\r\n            if isinstance(parsed_data, list):\r\n                result = [Data(data=item) for item in parsed_data]\r\n            else:\r\n                result = Data(data=parsed_data)\r\n\r\n            self.status = result\r\n            return result\r\n\r\n        except (json.JSONDecodeError, SyntaxError, ValueError) as e:\r\n            error_message = f\"Invalid JSON or Python literal: {str(e)}\"\r\n            error_data = Data(data={\"error\": error_message})\r\n            self.status = error_data\r\n            return error_data\r\n\r\n        except Exception as e:\r\n            error_message = f\"An error occurred: {str(e)}\"\r\n            error_data = Data(data={\"error\": error_message})\r\n            self.status = error_data\r\n            return error_data","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"json_string":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"json_string","display_name":"JSON String","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects","title_case":false,"type":"str"}},"description":"Convert a JSON string to a Data object or a list of Data objects","icon":"🔃","base_classes":["Data","List"],"display_name":"JSON to Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data","List"],"selected":"Data","name":"data","display_name":"Data","method":"convert_json_to_data","value":"__UNDEFINED__","cache":true}],"field_order":["json_string"],"beta":false,"edited":true,"official":false,"lf_version":"1.0.17"},"id":"AnthropicModel-E1MBw"},"selected":false,"width":384,"height":321},{"id":"DataBooleanSplitterComponent-m2KpK","type":"genericNode","position":{"x":6158.558993752975,"y":746.0158347116751},"data":{"type":"DataBooleanSplitterComponent","node":{"template":{"_type":"Component","data_input":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data_input","value":"","display_name":"Data Input","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The Data object to process","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.io import DataInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass DataBooleanSplitterComponent(Component):\r\n    display_name = \"Data Boolean Splitter\"\r\n    description = \"Split flow based on a boolean key in the input Data\"\r\n    icon = \"split\"\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"data_input\",\r\n            display_name=\"Data Input\",\r\n            info=\"The Data object to process\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"key_name\",\r\n            display_name=\"Key Name\",\r\n            info=\"The name of the key in the Data object to check for boolean value\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"process_data\"),\r\n        Output(display_name=\"False Output\", name=\"false_output\", method=\"process_data\"),\r\n    ]\r\n\r\n    def parse_boolean(self, value):\r\n        if isinstance(value, bool):\r\n            return value\r\n        if isinstance(value, str):\r\n            return value.lower() in ['true', '1', 'yes', 'y', 'on']\r\n        return bool(value)\r\n\r\n    def validate_input(self):\r\n        if not isinstance(self.data_input, Data):\r\n            self.status = \"Input is not a Data object\"\r\n            return False\r\n\r\n        if self.key_name not in self.data_input.data:\r\n            self.status = f\"Key '{self.key_name}' not found in Data\"\r\n            return False\r\n\r\n        return True\r\n\r\n    def process_data(self) -> Data:\r\n        if not self.validate_input():\r\n            return Data(data={\"error\": self.status})\r\n\r\n        boolean_value = self.parse_boolean(self.data_input.data[self.key_name])\r\n        \r\n        if boolean_value:\r\n            self.status = f\"Key '{self.key_name}' evaluated to True\"\r\n            self.stop(\"false_output\")\r\n            return self.data_input\r\n        else:\r\n            self.status = f\"Key '{self.key_name}' evaluated to False\"\r\n            self.stop(\"true_output\")\r\n            return self.data_input","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"key_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"key_name","value":"should_reply","display_name":"Key Name","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The name of the key in the Data object to check for boolean value","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Split flow based on a boolean key in the input Data","icon":"split","base_classes":["Data"],"display_name":"Data Boolean Splitter","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"true_output","display_name":"True Output","method":"process_data","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"false_output","display_name":"False Output","method":"process_data","value":"__UNDEFINED__","cache":true}],"field_order":["data_input","key_name"],"beta":false,"edited":true,"lf_version":"1.0.17"},"id":"DataBooleanSplitterComponent-m2KpK"},"selected":false,"width":384,"height":409},{"id":"WAHASendTextMessageComponent-rJDMy","type":"genericNode","position":{"x":8010.703993938703,"y":869.576867997084},"data":{"type":"WAHASendTextMessageComponent","node":{"template":{"_type":"Component","base_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"base_url","value":"http://api-whatsapp.namastex.ai:3000","display_name":"Base URL","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The base URL of the WAHA API.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"chat_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"chat_id","value":"chat ID here","display_name":"Chat ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The ID of the chat to send the message to.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import httpx\r\nfrom typing import Dict, Any, Optional\r\nfrom pydantic import BaseModel, Field\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.inputs import MessageTextInput\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass WAHASendTextMessageComponent(LCToolComponent):\r\n    display_name = \"WAHA - Send Text Message\"\r\n    description = \"Sends a text message to a specific chat using the WAHA API.\"\r\n    icon = \"message-circle-more\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"base_url\",\r\n            display_name=\"Base URL\",\r\n            info=\"The base URL of the WAHA API.\",\r\n            value=\"http://localhost:3000\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"session\",\r\n            display_name=\"Session\",\r\n            info=\"The session name.\",\r\n            value=\"default\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"chat_id\",\r\n            display_name=\"Chat ID\",\r\n            info=\"The ID of the chat to send the message to.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"text\",\r\n            display_name=\"Message Text\",\r\n            info=\"The text content of the message to send.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"reply_to\",\r\n            display_name=\"Reply To\",\r\n            info=\"The ID of the message to reply to (optional).\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    class WAHASendTextMessageSchema(BaseModel):\r\n        chat_id: str = Field(..., description=\"The ID of the chat to send the message to.\")\r\n        text: str = Field(..., description=\"The text content of the message to send.\")\r\n        reply_to: Optional[str] = Field(None, description=\"The ID of the message to reply to (optional).\")\r\n\r\n    def run_model(self) -> Data:\r\n        sent_message = self._send_text_message(self.chat_id, self.text, self.reply_to)\r\n        return Data(data=sent_message)\r\n\r\n    def build_tool(self) -> Tool:\r\n        return StructuredTool.from_function(\r\n            name=\"waha_send_text_message\",\r\n            description=\"Sends a text message to a specific chat using the WAHA API.\",\r\n            func=self._send_text_message,\r\n            args_schema=self.WAHASendTextMessageSchema,\r\n        )\r\n\r\n    def _send_text_message(self, chat_id: str, text: str, reply_to: Optional[str] = None) -> Dict[str, Any]:\r\n        url = f\"{self.base_url}/api/sendText\"\r\n        payload = {\r\n            \"chatId\": chat_id,\r\n            \"text\": text,\r\n            \"session\": self.session,\r\n        }\r\n        if reply_to:\r\n            payload[\"reply_to\"] = reply_to\r\n\r\n        headers = {\r\n            \"X-Api-Key\": \"{{apiKey}}\",  # Replace with actual API key handling\r\n            \"Content-Type\": \"application/json\",\r\n        }\r\n\r\n        self.log(f\"Sending POST request to {url}\")\r\n        with httpx.Client() as client:\r\n            response = client.post(url, json=payload, headers=headers)\r\n        response.raise_for_status()\r\n        sent_message = response.json()\r\n\r\n        self.log(\"Message sent successfully\")\r\n        return sent_message","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"reply_to":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"reply_to","value":"","display_name":"Reply To","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The ID of the message to reply to (optional).","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"session","value":"default","display_name":"Session","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The session name.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"text":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"text","value":"","display_name":"Message Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The text content of the message to send.","title_case":false,"type":"str","_input_type":"MessageTextInput"}},"description":"Sends a text message to a specific chat using the WAHA API.","icon":"message-circle-more","base_classes":["Data","Tool"],"display_name":"WAHA - Send Text Message","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"api_run_model","display_name":"Data","method":"run_model","value":"__UNDEFINED__","cache":true},{"types":["Tool"],"selected":"Tool","name":"api_build_tool","display_name":"Tool","method":"build_tool","value":"__UNDEFINED__","cache":true}],"field_order":["base_url","session","chat_id","text","reply_to"],"beta":false,"edited":true,"lf_version":"1.0.17","official":false},"id":"WAHASendTextMessageComponent-rJDMy"},"selected":false,"width":384,"height":623},{"id":"ParseData-Uq6d5","type":"genericNode","position":{"x":6620.982847370433,"y":614.8782594643992},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"Ta na hora de responder la man, já to te adiantando aqui e dando alou p pessoa. ","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"ParseData-Uq6d5"},"selected":false,"width":384,"height":369},{"id":"TextInput-cXpER","type":"genericNode","position":{"x":1117.6331276414462,"y":1139.0681178390694},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"{\n  \"event\": \"message\",\n  \"session\": \"default\",\n  \"metadata\": {},\n  \"me\": {\n    \"id\": \"555197285829@c.us\",\n    \"pushName\": \"Cezar Augusto\"\n  },\n  \"payload\": {\n    \"id\": \"false_555199550002@c.us_3BF457018FF3A1E9FC\",\n    \"timestamp\": 1725557150,\n    \"from\": \"555199550002@c.us\",\n    \"fromMe\": false,\n    \"to\": \"555197285829@c.us\",\n    \"body\": \"Oi, meu nome é RODRIGO. Em que posso ajudar? \\nSe ficarmos sem interação por 5 minutos, nossa conversa será automaticamente encerrada.\",\n    \"hasMedia\": false,\n    \"ack\": 1,\n    \"ackName\": \"SERVER\",\n    \"vCards\": [],\n    \"_data\": {\n      \"id\": {\n        \"fromMe\": false,\n        \"remote\": \"555199550002@c.us\",\n        \"id\": \"3BF457018FF3A1E9FC\",\n        \"_serialized\": \"false_555199550002@c.us_3BF457018FF3A1E9FC\"\n      },\n      \"viewed\": false,\n      \"body\": \"Oi, meu nome é RODRIGO. Em que posso ajudar? \\nSe ficarmos sem interação por 5 minutos, nossa conversa será automaticamente encerrada.\",\n      \"type\": \"chat\",\n      \"t\": 1725557150,\n      \"notifyName\": \"555199550002\",\n      \"from\": \"555199550002@c.us\",\n      \"to\": \"555197285829@c.us\",\n      \"ack\": 1,\n      \"invis\": false,\n      \"isNewMsg\": true,\n      \"star\": false,\n      \"kicNotified\": false,\n      \"recvFresh\": true,\n      \"isFromTemplate\": false,\n      \"pollInvalidated\": false,\n      \"isSentCagPollCreation\": false,\n      \"latestEditMsgKey\": null,\n      \"latestEditSenderTimestampMs\": null,\n      \"mentionedJidList\": [],\n      \"groupMentions\": [],\n      \"isEventCanceled\": false,\n      \"eventInvalidated\": false,\n      \"isVcardOverMmsDocument\": false,\n      \"isForwarded\": false,\n      \"hasReaction\": false,\n      \"privacyModeWhenSent\": {\n        \"actualActors\": 2,\n        \"hostStorage\": 1,\n        \"privacyModeTs\": 1619097475\n      },\n      \"productHeaderImageRejected\": false,\n      \"lastPlaybackProgress\": 0,\n      \"isDynamicReplyButtonsMsg\": false,\n      \"isCarouselCard\": false,\n      \"parentMsgId\": null,\n      \"isMdHistoryMsg\": false,\n      \"stickerSentTs\": 0,\n      \"isAvatar\": false,\n      \"lastUpdateFromServerTs\": 0,\n      \"invokedBotWid\": null,\n      \"bizBotType\": null,\n      \"botResponseTargetId\": null,\n      \"botPluginType\": null,\n      \"botPluginReferenceIndex\": null,\n      \"botPluginSearchProvider\": null,\n      \"botPluginSearchUrl\": null,\n      \"botPluginSearchQuery\": null,\n      \"botPluginMaybeParent\": false,\n      \"botReelPluginThumbnailCdnUrl\": null,\n      \"botMsgBodyType\": null,\n      \"requiresDirectConnection\": null,\n      \"bizContentPlaceholderType\": null,\n      \"hostedBizEncStateMismatch\": false,\n      \"senderOrRecipientAccountTypeHosted\": false,\n      \"placeholderCreatedWhenAccountIsHosted\": false,\n      \"links\": []\n    }\n  },\n  \"engine\": \"WEBJS\",\n  \"environment\": {\n    \"version\": \"2024.9.2\",\n    \"engine\": \"WEBJS\",\n    \"tier\": \"CORE\",\n    \"browser\": \"/usr/bin/chromium\"\n  }\n}","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Should Reply","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"TextInput-cXpER","description":"Get text inputs from the Playground.","display_name":"Text Input"},"selected":false,"width":384,"height":297},{"id":"JSONCleaner-THTrR","type":"genericNode","position":{"x":1591.7237662135922,"y":814.4154877814287},"data":{"type":"JSONCleaner","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\nimport re\nimport unicodedata\nfrom langflow.custom import Component\nfrom langflow.inputs import MessageTextInput, BoolInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\n\n\nclass JSONCleaner(Component):\n    display_name = \"JSON Cleaner\"\n    description = \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.\"\n    icon = \"custom_components\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import the json_repair package.\" \"Please install it with `pip install json_repair`.\"\n            )\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        try:\n            start = json_str.find(\"{\")\n            end = json_str.rfind(\"}\")\n            if start == -1 or end == -1:\n                raise ValueError(\"Invalid JSON string: Missing '{' or '}'\")\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            raise ValueError(f\"Error cleaning JSON string: {str(e)}\")\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", s)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n            return s\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON string: {str(e)}\")\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"json_str":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"json_str","value":"","display_name":"JSON String","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The JSON string to be cleaned.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"normalize_unicode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"normalize_unicode","value":true,"display_name":"Normalize Unicode","advanced":false,"dynamic":false,"info":"Normalize Unicode characters in the JSON string.","title_case":false,"type":"bool","_input_type":"BoolInput"},"remove_control_chars":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"remove_control_chars","value":false,"display_name":"Remove Control Characters","advanced":false,"dynamic":false,"info":"Remove control characters from the JSON string.","title_case":false,"type":"bool","_input_type":"BoolInput"},"validate_json":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"validate_json","value":false,"display_name":"Validate JSON","advanced":false,"dynamic":false,"info":"Validate the JSON string to ensure it is well-formed.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.","icon":"custom_components","base_classes":["Message"],"display_name":"JSON Cleaner","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"output","display_name":"Cleaned JSON String","method":"clean_json","value":"__UNDEFINED__","cache":true}],"field_order":["json_str","remove_control_chars","normalize_unicode","validate_json"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"JSONCleaner-THTrR"},"selected":false,"width":384,"height":569},{"id":"Prompt-A5xyl","type":"genericNode","position":{"x":7163.570154754008,"y":890.9489385675777},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":"Você é \"Fulano de tal\" seu CPF é 000.000.000-00 e você está começando uma conversa com um atendente da empresaTal para resolver questões da conta. \n\nNesse primeiro momento, apenas se apresente para o atendente. \n\nMensagem Atendente:\n{message}\n\n\nSeja sucinto, só fale o necessário. \n\n{nada}","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","_input_type":"PromptInput"},"message":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"message","display_name":"message","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"nada":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","name":"nada","display_name":"nada","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["message","nada"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-A5xyl"},"selected":false,"width":384,"height":497},{"id":"OpenAIModel-r5PDn","type":"genericNode","position":{"x":7584.80887694316,"y":873.0182389035269},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"name":"api_key","value":"","display_name":"OpenAI API Key","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageInput"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"json_mode","value":false,"display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool","_input_type":"BoolInput"},"max_tokens":{"trace_as_metadata":true,"range_spec":{"step_type":"float","min":0,"max":128000,"step":0.1},"list":false,"required":false,"placeholder":"","show":true,"name":"max_tokens","value":"","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int","_input_type":"IntInput"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"name":"model_kwargs","value":{},"display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict","_input_type":"DictInput"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o-mini","gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"combobox":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gpt-4o","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"openai_api_base","value":"","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str","_input_type":"StrInput"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"name":"output_schema","value":{},"display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict","_input_type":"DictInput"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"seed","value":1,"display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int","_input_type":"IntInput"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"stream","value":false,"display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool","_input_type":"BoolInput"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"system_message","value":"","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float","_input_type":"FloatInput"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","api_key","temperature","seed"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"OpenAIModel-r5PDn"},"selected":false,"width":384,"height":595},{"id":"ParseData-NpEUS","type":"genericNode","position":{"x":6619.382773862444,"y":1022.7271867078696},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_metadata":true,"list":false,"trace_as_input":true,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other","_input_type":"DataInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"sep","value":"\n","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"StrInput"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"template","value":" ","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str","_input_type":"MultilineInput"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false,"lf_version":"1.0.17"},"id":"ParseData-NpEUS"},"selected":false,"width":384,"height":369},{"id":"Webhook-i9Cws","type":"genericNode","position":{"x":3063.5939937407875,"y":1084.683841966166},"data":{"type":"Webhook","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\r\nimport re\r\nimport unicodedata\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MultilineInput, BoolInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass WebhookComponent(Component):\r\n    display_name = \"Webhook Input\"\r\n    description = \"Defines a webhook input for the flow with JSON cleaning capabilities.\"\r\n    name = \"Webhook\"\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"data\",\r\n            display_name=\"Data\",\r\n            info=\"Use this field to quickly test the webhook component by providing a JSON payload.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"remove_control_chars\",\r\n            display_name=\"Remove Control Characters\",\r\n            info=\"Remove control characters from the JSON string.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"normalize_unicode\",\r\n            display_name=\"Normalize Unicode\",\r\n            info=\"Normalize Unicode characters in the JSON string.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Data\", name=\"output_data\", method=\"build_data\"),\r\n    ]\r\n\r\n    def _remove_control_characters(self, s: str) -> str:\r\n        \"\"\"Remove control characters from the string.\"\"\"\r\n        return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", s)\r\n\r\n    def _normalize_unicode(self, s: str) -> str:\r\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\r\n        return unicodedata.normalize(\"NFC\", s)\r\n\r\n    def _clean_json(self, json_str: str) -> str:\r\n        \"\"\"Clean the JSON string.\"\"\"\r\n        try:\r\n            from json_repair import repair_json\r\n        except ImportError:\r\n            raise ImportError(\r\n                \"Could not import the json_repair package. \"\r\n                \"Please install it with `pip install json_repair`.\"\r\n            )\r\n\r\n        start = json_str.find(\"{\")\r\n        end = json_str.rfind(\"}\")\r\n        if start == -1 or end == -1:\r\n            raise ValueError(\"Invalid JSON string: Missing '{' or '}'\")\r\n        json_str = json_str[start : end + 1]\r\n\r\n        if self.remove_control_chars:\r\n            json_str = self._remove_control_characters(json_str)\r\n        if self.normalize_unicode:\r\n            json_str = self._normalize_unicode(json_str)\r\n\r\n        return repair_json(json_str)\r\n\r\n    def build_data(self) -> Data:\r\n        if not self.data:\r\n            return Data(data={\"message\": \"No data provided.\"})\r\n\r\n        try:\r\n            cleaned_json_str = self._clean_json(self.data)\r\n            body = json.loads(cleaned_json_str)\r\n            return Data(data=body)\r\n        except json.JSONDecodeError as e:\r\n            return Data(data={\r\n                \"error\": \"Invalid JSON payload\",\r\n                \"message\": f\"Please check the format: {str(e)}\",\r\n                \"raw_data\": self.data\r\n            })\r\n        except Exception as e:\r\n            return Data(data={\r\n                \"error\": \"Error processing data\",\r\n                \"message\": str(e),\r\n                \"raw_data\": self.data\r\n            })","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"data","value":"","display_name":"Data","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Use this field to quickly test the webhook component by providing a JSON payload.","title_case":false,"type":"str","_input_type":"MultilineInput"},"normalize_unicode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"normalize_unicode","value":true,"display_name":"Normalize Unicode","advanced":false,"dynamic":false,"info":"Normalize Unicode characters in the JSON string.","title_case":false,"type":"bool","_input_type":"BoolInput"},"remove_control_chars":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"remove_control_chars","value":false,"display_name":"Remove Control Characters","advanced":false,"dynamic":false,"info":"Remove control characters from the JSON string.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Defines a webhook input for the flow with JSON cleaning capabilities.","base_classes":["Data"],"display_name":"Webhook Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output_data","display_name":"Data","method":"build_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","remove_control_chars","normalize_unicode"],"beta":false,"edited":true},"id":"Webhook-i9Cws"},"selected":false,"width":384,"height":469},{"id":"JSONCleaner-mRzfk","type":"genericNode","position":{"x":2607.6811701806423,"y":1153.654771674938},"data":{"type":"JSONCleaner","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import json\nimport re\nimport unicodedata\nfrom langflow.custom import Component\nfrom langflow.inputs import MessageTextInput, BoolInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\n\n\nclass JSONCleaner(Component):\n    display_name = \"JSON Cleaner\"\n    description = \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.\"\n    icon = \"custom_components\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import the json_repair package.\" \"Please install it with `pip install json_repair`.\"\n            )\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        try:\n            start = json_str.find(\"{\")\n            end = json_str.rfind(\"}\")\n            if start == -1 or end == -1:\n                raise ValueError(\"Invalid JSON string: Missing '{' or '}'\")\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            raise ValueError(f\"Error cleaning JSON string: {str(e)}\")\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", s)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n            return s\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON string: {str(e)}\")\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"json_str":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"name":"json_str","value":"","display_name":"JSON String","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The JSON string to be cleaned.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"normalize_unicode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"normalize_unicode","value":false,"display_name":"Normalize Unicode","advanced":false,"dynamic":false,"info":"Normalize Unicode characters in the JSON string.","title_case":false,"type":"bool","_input_type":"BoolInput"},"remove_control_chars":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"remove_control_chars","value":false,"display_name":"Remove Control Characters","advanced":false,"dynamic":false,"info":"Remove control characters from the JSON string.","title_case":false,"type":"bool","_input_type":"BoolInput"},"validate_json":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"name":"validate_json","value":false,"display_name":"Validate JSON","advanced":false,"dynamic":false,"info":"Validate the JSON string to ensure it is well-formed.","title_case":false,"type":"bool","_input_type":"BoolInput"}},"description":"Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.","icon":"custom_components","base_classes":["Message"],"display_name":"JSON Cleaner","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"output","display_name":"Cleaned JSON String","method":"clean_json","value":"__UNDEFINED__","cache":true}],"field_order":["json_str","remove_control_chars","normalize_unicode","validate_json"],"beta":false,"edited":false},"id":"JSONCleaner-mRzfk"},"selected":false,"width":384,"height":569}],"edges":[{"source":"WAHAMessageParser-vFNUP","target":"ConditionalRouter-5qC0k","sourceHandle":"{œdataTypeœ:œWAHAMessageParserœ,œidœ:œWAHAMessageParser-vFNUPœ,œnameœ:œfromœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-5qC0kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-WAHAMessageParser-vFNUP{œdataTypeœ:œWAHAMessageParserœ,œidœ:œWAHAMessageParser-vFNUPœ,œnameœ:œfromœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-5qC0k{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-5qC0kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_text","id":"ConditionalRouter-5qC0k","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"WAHAMessageParser","id":"WAHAMessageParser-vFNUP","name":"from","output_types":["Message"]}},"selected":false},{"source":"WAHAMessageParser-vFNUP","target":"ConditionalRouter-5qC0k","sourceHandle":"{œdataTypeœ:œWAHAMessageParserœ,œidœ:œWAHAMessageParser-vFNUPœ,œnameœ:œbodyœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-5qC0kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-WAHAMessageParser-vFNUP{œdataTypeœ:œWAHAMessageParserœ,œidœ:œWAHAMessageParser-vFNUPœ,œnameœ:œbodyœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-5qC0k{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-5qC0kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"message","id":"ConditionalRouter-5qC0k","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"WAHAMessageParser","id":"WAHAMessageParser-vFNUP","name":"body","output_types":["Message"]}},"selected":false},{"source":"WAHAGetChatMessagesComponent-JSlLF","target":"ParseData-ztNLm","sourceHandle":"{œdataTypeœ:œWAHAGetChatMessagesComponentœ,œidœ:œWAHAGetChatMessagesComponent-JSlLFœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-ztNLmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","id":"reactflow__edge-WAHAGetChatMessagesComponent-JSlLF{œdataTypeœ:œWAHAGetChatMessagesComponentœ,œidœ:œWAHAGetChatMessagesComponent-JSlLFœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}-ParseData-ztNLm{œfieldNameœ:œdataœ,œidœ:œParseData-ztNLmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-ztNLm","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"WAHAGetChatMessagesComponent","id":"WAHAGetChatMessagesComponent-JSlLF","name":"api_run_model","output_types":["Data"]}},"selected":false},{"source":"ParseData-ztNLm","target":"Prompt-1ADTy","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-ztNLmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œold_messagesœ,œidœ:œPrompt-1ADTyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-ParseData-ztNLm{œdataTypeœ:œParseDataœ,œidœ:œParseData-ztNLmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-1ADTy{œfieldNameœ:œold_messagesœ,œidœ:œPrompt-1ADTyœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"old_messages","id":"Prompt-1ADTy","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-ztNLm","name":"text","output_types":["Message"]}},"selected":false},{"source":"Prompt-1ADTy","target":"AnthropicModel-KryHb","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-1ADTyœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-KryHbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-Prompt-1ADTy{œdataTypeœ:œPromptœ,œidœ:œPrompt-1ADTyœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-KryHb{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-KryHbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AnthropicModel-KryHb","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-1ADTy","name":"prompt","output_types":["Message"]}},"selected":false},{"source":"AnthropicModel-KryHb","target":"WAHASendTextMessageComponent-n5hG9","sourceHandle":"{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-KryHbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œtextœ,œidœ:œWAHASendTextMessageComponent-n5hG9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-AnthropicModel-KryHb{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-KryHbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-WAHASendTextMessageComponent-n5hG9{œfieldNameœ:œtextœ,œidœ:œWAHASendTextMessageComponent-n5hG9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"text","id":"WAHASendTextMessageComponent-n5hG9","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"AnthropicModel","id":"AnthropicModel-KryHb","name":"text_output","output_types":["Message"]}},"selected":false},{"source":"Prompt-EuZGR","target":"OpenAIModel-828dg","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-EuZGRœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-828dgœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-Prompt-EuZGR{œdataTypeœ:œPromptœ,œidœ:œPrompt-EuZGRœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-828dg{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-828dgœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-828dg","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-EuZGR","name":"prompt","output_types":["Message"]}},"selected":false},{"source":"OpenAIModel-828dg","target":"AnthropicModel-E1MBw","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-828dgœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œjson_stringœ,œidœ:œAnthropicModel-E1MBwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-OpenAIModel-828dg{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-828dgœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-E1MBw{œfieldNameœ:œjson_stringœ,œidœ:œAnthropicModel-E1MBwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"json_string","id":"AnthropicModel-E1MBw","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-828dg","name":"text_output","output_types":["Message"]}},"selected":false},{"source":"AnthropicModel-E1MBw","target":"DataBooleanSplitterComponent-m2KpK","sourceHandle":"{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-E1MBwœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}","targetHandle":"{œfieldNameœ:œdata_inputœ,œidœ:œDataBooleanSplitterComponent-m2KpKœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","id":"reactflow__edge-AnthropicModel-E1MBw{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-E1MBwœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-DataBooleanSplitterComponent-m2KpK{œfieldNameœ:œdata_inputœ,œidœ:œDataBooleanSplitterComponent-m2KpKœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data_input","id":"DataBooleanSplitterComponent-m2KpK","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"AnthropicModel","id":"AnthropicModel-E1MBw","name":"data","output_types":["Data"]}},"selected":false},{"source":"DataBooleanSplitterComponent-m2KpK","target":"ParseData-Uq6d5","sourceHandle":"{œdataTypeœ:œDataBooleanSplitterComponentœ,œidœ:œDataBooleanSplitterComponent-m2KpKœ,œnameœ:œtrue_outputœ,œoutput_typesœ:[œDataœ]}","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-Uq6d5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","id":"reactflow__edge-DataBooleanSplitterComponent-m2KpK{œdataTypeœ:œDataBooleanSplitterComponentœ,œidœ:œDataBooleanSplitterComponent-m2KpKœ,œnameœ:œtrue_outputœ,œoutput_typesœ:[œDataœ]}-ParseData-Uq6d5{œfieldNameœ:œdataœ,œidœ:œParseData-Uq6d5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-Uq6d5","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"DataBooleanSplitterComponent","id":"DataBooleanSplitterComponent-m2KpK","name":"true_output","output_types":["Data"]}},"selected":false},{"source":"TextInput-cXpER","target":"JSONCleaner-THTrR","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-cXpERœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-THTrRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-TextInput-cXpER{œdataTypeœ:œTextInputœ,œidœ:œTextInput-cXpERœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-JSONCleaner-THTrR{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-THTrRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"json_str","id":"JSONCleaner-THTrR","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-cXpER","name":"text","output_types":["Message"]}},"selected":false},{"source":"Prompt-A5xyl","target":"OpenAIModel-r5PDn","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-A5xylœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-r5PDnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-Prompt-A5xyl{œdataTypeœ:œPromptœ,œidœ:œPrompt-A5xylœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-r5PDn{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-r5PDnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-r5PDn","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-A5xyl","name":"prompt","output_types":["Message"]}},"selected":false},{"source":"ConditionalRouter-5qC0k","target":"Prompt-EuZGR","sourceHandle":"{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5qC0kœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œmessageœ,œidœ:œPrompt-EuZGRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-ConditionalRouter-5qC0k{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-5qC0kœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt-EuZGR{œfieldNameœ:œmessageœ,œidœ:œPrompt-EuZGRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"message","id":"Prompt-EuZGR","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ConditionalRouter","id":"ConditionalRouter-5qC0k","name":"true_result","output_types":["Message"]}},"selected":false},{"source":"OpenAIModel-r5PDn","target":"WAHASendTextMessageComponent-rJDMy","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-r5PDnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œtextœ,œidœ:œWAHASendTextMessageComponent-rJDMyœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-OpenAIModel-r5PDn{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-r5PDnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-WAHASendTextMessageComponent-rJDMy{œfieldNameœ:œtextœ,œidœ:œWAHASendTextMessageComponent-rJDMyœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"text","id":"WAHASendTextMessageComponent-rJDMy","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-r5PDn","name":"text_output","output_types":["Message"]}},"selected":false},{"source":"JSONCleaner-THTrR","target":"AnthropicModel-2Z3iK","sourceHandle":"{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-THTrRœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œjson_stringœ,œidœ:œAnthropicModel-2Z3iKœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","id":"reactflow__edge-JSONCleaner-THTrR{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-THTrRœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-2Z3iK{œfieldNameœ:œjson_stringœ,œidœ:œAnthropicModel-2Z3iKœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"json_string","id":"AnthropicModel-2Z3iK","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"JSONCleaner","id":"JSONCleaner-THTrR","name":"output","output_types":["Message"]}},"selected":false},{"source":"WAHAMessageParser-vFNUP","target":"Prompt-A5xyl","sourceHandle":"{œdataTypeœ:œWAHAMessageParserœ,œidœ:œWAHAMessageParser-vFNUPœ,œnameœ:œbodyœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œmessageœ,œidœ:œPrompt-A5xylœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-WAHAMessageParser-vFNUP{œdataTypeœ:œWAHAMessageParserœ,œidœ:œWAHAMessageParser-vFNUPœ,œnameœ:œbodyœ,œoutput_typesœ:[œMessageœ]}-Prompt-A5xyl{œfieldNameœ:œmessageœ,œidœ:œPrompt-A5xylœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"message","id":"Prompt-A5xyl","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"WAHAMessageParser","id":"WAHAMessageParser-vFNUP","name":"body","output_types":["Message"]}},"selected":false},{"source":"ParseData-NpEUS","target":"Prompt-A5xyl","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-NpEUSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","targetHandle":"{œfieldNameœ:œnadaœ,œidœ:œPrompt-A5xylœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-ParseData-NpEUS{œdataTypeœ:œParseDataœ,œidœ:œParseData-NpEUSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-A5xyl{œfieldNameœ:œnadaœ,œidœ:œPrompt-A5xylœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"nada","id":"Prompt-A5xyl","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-NpEUS","name":"text","output_types":["Message"]}},"selected":false},{"source":"DataBooleanSplitterComponent-m2KpK","target":"ParseData-NpEUS","sourceHandle":"{œdataTypeœ:œDataBooleanSplitterComponentœ,œidœ:œDataBooleanSplitterComponent-m2KpKœ,œnameœ:œtrue_outputœ,œoutput_typesœ:[œDataœ]}","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-NpEUSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","id":"reactflow__edge-DataBooleanSplitterComponent-m2KpK{œdataTypeœ:œDataBooleanSplitterComponentœ,œidœ:œDataBooleanSplitterComponent-m2KpKœ,œnameœ:œtrue_outputœ,œoutput_typesœ:[œDataœ]}-ParseData-NpEUS{œfieldNameœ:œdataœ,œidœ:œParseData-NpEUSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-NpEUS","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"DataBooleanSplitterComponent","id":"DataBooleanSplitterComponent-m2KpK","name":"true_output","output_types":["Data"]}},"selected":false},{"source":"Webhook-i9Cws","target":"WAHAMessageParser-vFNUP","sourceHandle":"{œdataTypeœ:œWebhookœ,œidœ:œWebhook-i9Cwsœ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}","targetHandle":"{œfieldNameœ:œinput_dataœ,œidœ:œWAHAMessageParser-vFNUPœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","id":"reactflow__edge-Webhook-i9Cws{œdataTypeœ:œWebhookœ,œidœ:œWebhook-i9Cwsœ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}-WAHAMessageParser-vFNUP{œfieldNameœ:œinput_dataœ,œidœ:œWAHAMessageParser-vFNUPœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"input_data","id":"WAHAMessageParser-vFNUP","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"Webhook","id":"Webhook-i9Cws","name":"output_data","output_types":["Data"]}},"selected":false}],"viewport":{"x":-3736.0169290882004,"y":-1552.712715491,"zoom":0.6597539553864477}},"description":"Create, Curate, Communicate with Langflow.","name":"waha_playground","last_tested_version":"1.0.18","endpoint_name":null,"is_component":false}